# -*- coding: utf-8 -*-
"""CardanoResnet1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zmfKFPgag3L-6QSBp8TLMmqs-5Ot11e3
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import torch
import torchvision
import torch.nn as nn
import numpy as np
import torch.nn.functional as F
import torchvision.transforms as tt
import torchvision.models as models
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import torchvision.transforms as tt
from torch.utils.data import random_split
from torchvision.utils import make_grid
from copy import copy
# %matplotlib inline



from google.colab import drive
drive.mount('/content/gdrive')

!unzip gdrive/MyDrive/data/archive.zip

classes = os.listdir( "./asl_alphabet_train/asl_alphabet_train")
print(classes)

x = 0
for letter in classes:
    x = x + 1

print(str(x) + " classes")

dataset = ImageFolder('./asl_alphabet_train/asl_alphabet_train')

# Data transforms (normalization and data augmentation)
#stats = ((0.5190, 0.4992, 0.5140),(0.2038, 0.2283, 0.2356))
train_tfms = tt.Compose([tt.RandomCrop(200, padding=25, padding_mode='reflect'),
                        tt.RandomHorizontalFlip(), 
                        tt.RandomRotation(10),
                        tt.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
                        tt.RandomPerspective(distortion_scale=0.2),
                        tt.ToTensor(),
                        tt.Normalize([0.485, 0.456, 0.406],
                        [0.229, 0.224, 0.225])])

valid_tfms = tt.Compose([tt.Resize((225, 225)),
                         tt.ToTensor(),
                         tt.Normalize([0.485, 0.456, 0.406],
                        [0.229, 0.224, 0.225])])

val_size = int(0.15 * len(dataset))
train_size = len(dataset) - val_size

train_ds, valid_ds = random_split(dataset, [train_size, val_size])
len(train_ds), len(valid_ds)

train_ds.dataset = copy(dataset)
train_ds.dataset.transform = train_tfms
valid_ds.dataset.transform = valid_tfms

# Pytorch Datasets
# train_ds = ImageFolder("./asl_alphabet_train/asl_alphabet_train", train_tfms)
# test_ds = ImageFolder("./asl_alphabet_test", valid_tfms)

# HyperParameters
batch_size = 50

random_seed = 23
torch.manual_seed(random_seed);

# Pytorch data loaders
train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)
valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=4, pin_memory=True)

def to_device(data, device):
    # Move Tensors to a chosen device
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    # Move Data to the device
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
    
    def __iter__(self):
        for batch in self.dl:
            yield to_device(batch, self.device)
            
    def __len__(self):
        # Number of batches
        return len(self.dl)

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(device)

train_dl = DeviceDataLoader(train_dl, device)
valid_dl = DeviceDataLoader(valid_dl, device)

print(train_dl.device)
print(valid_dl.device)

# Create Network class and make helper methods for training and validation
class Network(nn.Module):
    def training_step(self, batch):
        images, labels = batch 
        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate loss
        return loss
    
    def validation_step(self, batch):
        images, labels = batch 
        out = self(images)                    # Generate predictions
        loss = F.cross_entropy(out, labels)   # Calculate loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_acc': acc, 'val_loss': loss.detach()}
        
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_acc': epoch_acc.item(), 'val_loss': epoch_loss.item()}
    
    def epoch_end(self, epoch, result):
        print("Epoch [{}], val_acc: {:.4f}, val_loss: {:.4f}".format(epoch, result['val_acc'], result['val_loss']))

def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

# def conv_block(in_channels, out_channels, pool=False):
#     layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
#              nn.BatchNorm2d(out_channels),
#              nn.ReLU(inplace=True)]
#     if pool == True: 
#         layers.append(nn.MaxPool2d(2))
    
#     return nn.Sequential(*layers)
    
    # Create Residual Network with Resnet50 architecture
class ResNet152(Network):
    def __init__(self):
        super().__init__()
        # Use a pretrained model
        self.network = models.resnet152(pretrained=True)
        # Replace last layer
        num_ftrs = self.network.fc.in_features
        self.network.fc = nn.Linear(num_ftrs, 29)
    
    def forward(self, xb):
        return self.network(xb)

model = to_device(ResNet152(), device)
model

@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']

def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, 
                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):
    torch.cuda.empty_cache()
    history = []
    
    # Set up cutom optimizer with weight decay
    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)
    # Set up one-cycle learning rate scheduler
    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, 
                                                steps_per_epoch=len(train_loader))
    
    for epoch in range(epochs):
        # Training Phase 
        model.train()
        train_losses = []
        lrs = []
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            
            # Gradient clipping
            if grad_clip: 
                nn.utils.clip_grad_value_(model.parameters(), grad_clip)
            
            optimizer.step()
            optimizer.zero_grad()
            
            # Record & update learning rate
            lrs.append(get_lr(optimizer))
            sched.step()
        
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        result['lrs'] = lrs
        model.epoch_end(epoch, result)
        history.append(result)
    return history

history = [evaluate(model, valid_dl)]
history

#model.freeze()

epochs = 2
max_lr = 1e-5
grad_clip = 0.001
weight_decay = 1e-5
opt_func = torch.optim.SGD

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history += fit_one_cycle(2, max_lr, model, train_dl, valid_dl, 
#                              grad_clip=grad_clip, 
#                              weight_decay=weight_decay, 
#                              opt_func=torch.optim.AdamW)

history = [evaluate(model, valid_dl)]
history

# %%time
# history += fit_one_cycle(5, 1e-5, model, train_dl, valid_dl, 
#                              grad_clip=grad_clip, 
#                              weight_decay=weight_decay, 
#                              opt_func=torch.optim.Adam)

# %%time
# history += fit_one_cycle(3, 1e-5, model, train_dl, valid_dl, 
#                              grad_clip=grad_clip, 
#                              weight_decay=weight_decay, 
#                              opt_func=torch.optim.SGD)

model.eval()

# Save Pytorch Model
FILE = "gdrive/MyDrive/data/modelResNet9.pth"
torch.save(model.state_dict(), FILE)



onnx_model_path = "gdrive/MyDrive/data/modelResNet9.onnx"
x = torch.randn(1, 3, 225, 225, device=device) # Sample input in the shape that the model expects
torch.onnx.export(model, x, onnx_model_path, export_params=True, verbose=True,)

!unzip gdrive/MyDrive/data/archiveTest.zip

test_dataset = ImageFolder('./asl-alphabet-testR')
test_ds, _ = random_split(test_dataset, [len(test_dataset), 0])
test_ds.dataset.transform = tt.Compose([tt.Resize((225, 225)), tt.ToTensor()])
test_dl = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)

test_dl = DeviceDataLoader(test_dl, device)

evaluate(model, test_dl)

def predict_image(img, model):
    # Convert to a batch of 1
    xb = to_device(img.unsqueeze(0), device)
    # Get predictions from model
    yb = model(xb)
    # Pick index with highest probability
    _, preds  = torch.max(yb, dim=1)
    # Retrieve the class label
    return dataset.classes[preds[0].item()]

test_dataset = ImageFolder('./asl-alphabet-testR')
test_ds, _ = random_split(test_dataset, [len(test_dataset), 0])
test_ds.dataset.transform = tt.Compose([tt.ToTensor()])

img, label = test_ds[16]
print('Label:', test_dataset.classes[label])
print('Predicted:', predict_image(img, model))

img, label = test_ds[1]
print('Label:', test_dataset.classes[label])
print('Predicted:', predict_image(img, model))

img, label = test_ds[0]
print('Label:', test_dataset.classes[label])
print('Predicted:', predict_image(img, model))

x = 0
while x <= 20:
  img, label = test_ds[x]
  print('Label:', test_dataset.classes[label])
  print('Predicted:', predict_image(img, model))
  print()
  x = x + 1