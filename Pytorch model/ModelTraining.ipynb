{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8jwUmwJdd-s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tt\n",
        "import torchvision.models as models\n",
        "from torchvision.transforms.transforms import Resize\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "from copy import copy\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Elv3iZMyP42v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f87ca67-e64a-4527-d6b5-2bb14230cc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Au0xuZZi5CY"
      },
      "outputs": [],
      "source": [
        "!unzip gdrive/MyDrive/data/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ9KEPgji93u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a4119b-a01b-4392-9c04-d27a5af4ea0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['space', 'O', 'T', 'N', 'Y', 'G', 'K', 'Q', 'J', 'nothing', 'A', 'M', 'P', 'X', 'R', 'B', 'L', 'C', 'W', 'V', 'del', 'D', 'F', 'U', 'S', 'Z', 'E', 'I', 'H']\n",
            "29 classes\n"
          ]
        }
      ],
      "source": [
        "classes = os.listdir( \"./asl_alphabet_train/asl_alphabet_train\")\n",
        "print(classes)\n",
        "\n",
        "x = 0\n",
        "for letter in classes:\n",
        "    x = x + 1\n",
        "\n",
        "print(str(x) + \" classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teq-OJIzJ767"
      },
      "outputs": [],
      "source": [
        "dataset = ImageFolder('./asl_alphabet_train/asl_alphabet_train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSD9qJv-jOKP"
      },
      "outputs": [],
      "source": [
        "# Data transforms (normalization and data augmentation)\n",
        "train_tfms = tt.Compose([tt.Resize((224, 224)),\n",
        "                         tt.RandomCrop(224, padding=28, padding_mode='constant', fill=(0,0,0)),\n",
        "                         tt.RandomHorizontalFlip(p=0.3), \n",
        "                         tt.RandomRotation(30),\n",
        "                         tt.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                         tt.RandomPerspective(distortion_scale=0.2),\n",
        "                         tt.ToTensor(),\n",
        "                         tt.Normalize([0.485, 0.456, 0.406],\n",
        "                        [0.229, 0.224, 0.225])])\n",
        "\n",
        "valid_tfms = tt.Compose([tt.Resize((224, 224)),\n",
        "                         tt.ToTensor(),\n",
        "                         tt.Normalize([0.485, 0.456, 0.406],\n",
        "                        [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SHsNt7_J1gJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b316cb-0e7b-4880-e20b-9de15fbc40d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73950, 13050)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "val_size = int(0.15 * len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_ds, valid_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(valid_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yku8dlpEKdbr"
      },
      "outputs": [],
      "source": [
        "train_ds.dataset = copy(dataset)\n",
        "train_ds.dataset.transform = train_tfms\n",
        "valid_ds.dataset.transform = valid_tfms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSMwu0h7jPdI"
      },
      "outputs": [],
      "source": [
        "# Pytorch Datasets\n",
        "# train_ds = ImageFolder(\"./asl_alphabet_train/asl_alphabet_train\", train_tfms)\n",
        "# test_ds = ImageFolder(\"./asl_alphabet_test\", valid_tfms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIaxWUxLjQ6o"
      },
      "outputs": [],
      "source": [
        "# HyperParameters\n",
        "batch_size = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy60v1uRLLyF"
      },
      "outputs": [],
      "source": [
        "random_seed = 23\n",
        "torch.manual_seed(random_seed);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXpSjFV2jR_g"
      },
      "outputs": [],
      "source": [
        "# Pytorch data loaders\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HRGkSU8jTWi"
      },
      "outputs": [],
      "source": [
        "def to_device(data, device):\n",
        "    # Move Tensors to a chosen device\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    # Move Data to the device\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            yield to_device(batch, self.device)\n",
        "            \n",
        "    def __len__(self):\n",
        "        # Number of batches\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQTMTHV7jUvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3788288a-4bae-43ee-f3f2-3d5f631dad70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "cuda\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)\n",
        "\n",
        "print(train_dl.device)\n",
        "print(valid_dl.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPVR1xzPjV2D"
      },
      "outputs": [],
      "source": [
        "# Create Network class and make helper methods for training and validation\n",
        "class Network(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_acc': acc, 'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_acc': epoch_acc.item(), 'val_loss': epoch_loss.item()}\n",
        "\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_acc: {:.4f}, val_loss: {:.4f}\".format(epoch, result['val_acc'], result['val_loss']))\n",
        "        return True\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD1rhMLnjYAT"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ResNet152(Network):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet152(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, 29)\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "\n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = False\n",
        "        for param in self.network.fc.parameters():\n",
        "            param.require_grad = True\n",
        "        return True\n",
        "    \n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = True\n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCykiPkskAI8"
      },
      "outputs": [],
      "source": [
        "model = to_device(ResNet152(), device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h43XSabLkCFo"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    \n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            \n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8w0N3QRkF4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f08bf56-6aac-474d-d2e6-4f85e5e15d97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_acc': 0.04793892800807953, 'val_loss': 3.437835693359375}]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "history = [evaluate(model, valid_dl)]\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDJotxw9vR3e"
      },
      "outputs": [],
      "source": [
        "# model.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJXRuVb3kHwt"
      },
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "max_lr = 1e-5\n",
        "grad_clip = 0.001\n",
        "weight_decay = 1e-5\n",
        "opt_func = torch.optim.AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY4PkYJXkJMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a26b65-604a-4179-e77b-41b08bb9f8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_acc: 0.9992, val_loss: 0.0190\n",
            "CPU times: user 10min 22s, sys: 5min 48s, total: 16min 10s\n",
            "Wall time: 15min 48s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.unfreeze()"
      ],
      "metadata": {
        "id": "FrdvpHuSp6HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGpzW1BQqASh",
        "outputId": "636ddc04-ee3d-4b2e-90aa-86bbdbe896c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_acc: 1.0000, val_loss: 0.0019\n",
            "CPU times: user 10min 23s, sys: 5min 47s, total: 16min 10s\n",
            "Wall time: 15min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = [evaluate(model, valid_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "zBVVaf-WBH6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d8b3c6-8380-4b22-925c-a81021f09f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_acc': 1.0, 'val_loss': 0.0018670875579118729}]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "M1qmdtJ8c2aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vizYaeGIRjmG"
      },
      "outputs": [],
      "source": [
        "# Save Pytorch Model\n",
        "FILE = \"gdrive/MyDrive/data/modelResNet12.pth\"\n",
        "torch.save(model.state_dict(), FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7crXLw_T4xs"
      },
      "outputs": [],
      "source": [
        "# onnx_model_path = \"gdrive/MyDrive/data/modelResNetV10.onnx\"\n",
        "# x = torch.randn(50, 3, 200, 200, device=device) # Sample input in the shape that the model expects\n",
        "# torch.onnx.export(model, x, onnx_model_path, export_params=True, verbose=True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF5n0sEgMpCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682072ad-f633-435e-9087-d740991253a5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  gdrive/MyDrive/data/archiveTest.zip\n",
            "replace A/A0001_test.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip gdrive/MyDrive/data/archiveTest.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKsLjMUQNXVB"
      },
      "outputs": [],
      "source": [
        "test_dataset = ImageFolder('./asl-alphabet-testR')\n",
        "test_ds, _ = random_split(test_dataset, [len(test_dataset), 0])\n",
        "test_ds.dataset.transform = tt.Compose([tt.Resize((224, 224)),\n",
        "                         tt.RandomCrop(224, padding=28, padding_mode='constant', fill=(0,0,0)),\n",
        "                         tt.RandomHorizontalFlip(p=0.3), \n",
        "                         tt.RandomRotation(30),\n",
        "                         tt.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                         tt.RandomPerspective(distortion_scale=0.2),\n",
        "                         tt.ToTensor(),\n",
        "                         tt.Normalize([0.485, 0.456, 0.406],\n",
        "                        [0.229, 0.224, 0.225])\n",
        "                         ])\n",
        "test_dl = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffaDvbv0N6XM"
      },
      "outputs": [],
      "source": [
        "test_dl = DeviceDataLoader(test_dl, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP9XYuRmN8lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6e51eb-e279-41f6-e8eb-60c1ecf4df65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.8022222518920898, 'val_loss': 0.7864134907722473}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "evaluate(model, test_dl)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return dataset.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "JPAWBxG2G4qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import io"
      ],
      "metadata": {
        "id": "h8YvbRCT1T3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/gdrive/MyDrive/data/model/test_B.jpg')\n",
        "img = tt.functional.rotate(img, angle=270)\n",
        "img = valid_tfms(img)"
      ],
      "metadata": {
        "id": "fdQIms4A1dA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.shape)\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "tCQJXFn01l7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d731f5-c575-45e8-962e-a8fb1146c4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "Predicted: B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = ImageFolder('./asl-alphabet-testR')\n",
        "test_ds, _ = random_split(test_dataset, [len(test_dataset), 0])\n",
        "test_ds.dataset.transform = tt.Compose([tt.ToTensor()])"
      ],
      "metadata": {
        "id": "dBdmagBoG6w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_ds[16]\n",
        "print('Label:', test_dataset.classes[label])\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "15AKAiVPHRFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_ds[1]\n",
        "print('Label:', test_dataset.classes[label])\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "RfbBQKV_HXON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_ds[0]\n",
        "print('Label:', test_dataset.classes[label])\n",
        "print('Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "wK7dH3fAHdT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6595fe3e-a98c-4f14-920d-253493106b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: space\n",
            "Predicted: space\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = 60\n",
        "while x <= 100:\n",
        "  img, label = test_ds[x]\n",
        "  print('Expected Ouput:', test_dataset.classes[label])\n",
        "  print('Predicted Output:', predict_image(img, model))\n",
        "  print()\n",
        "  x = x + 1"
      ],
      "metadata": {
        "id": "si6ZssUcHiCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CardanoResnet1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}